{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Maligireddy_Assignment5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center>\n",
        "\n",
        "# Assignment 5: Naive Bayes Learning\n",
        "\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "u-Uh0vRIDHwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Jalendar Reddy Maligireddy**\n",
        "\n",
        "# 11511290"
      ],
      "metadata": {
        "id": "AKs0StI4Dbu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.About the model"
      ],
      "metadata": {
        "id": "mPuzMdfnDmw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes is a machine learning model that is used for big amounts of data; even if you are dealing with data that contains millions of records, Naive Bayes is the preferred strategy. When it comes to NLP tasks like sentiment analysis, it produces excellent results. It is a simple and quick categorization method."
      ],
      "metadata": {
        "id": "Cw_YEBYIFX_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P(A|B) = P(B|A).P(A)/P(B)\n",
        "\n",
        "Where, \n",
        "\n",
        "P(A): The probability of hypothesis H being true. This is known as the prior probability.\n",
        "\n",
        "P(B): The probability of the evidence.\n",
        "\n",
        "P(A|B): The probability of the evidence given that hypothesis is true.  \n",
        "\n",
        "P(B|A): The probability of the hypothesis given that the evidence is true."
      ],
      "metadata": {
        "id": "m8J6sreLGlVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A classifier is a machine learning model that distinguishes between different objects based on variable properties.\n",
        "\n",
        "It is a classifier that is based on the Bayes theorem. Membership probabilities, such as the likelihood of data points belonging to a certain class, are predicted for each class.\n",
        "\n",
        "The most likely class is designated as the most appropriate class. This is also referred to as Maximum A Posteriori (MAP)."
      ],
      "metadata": {
        "id": "9GNHoXiFHKkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of Naive Bayes Algorithms\n",
        "\n",
        "1. Gaussian Nave Bayes: When characteristic values are continuous in nature, it is assumed that the values associated with each class are scattered according to the Gaussian distribution, which is the Normal Distribution.\n",
        "2. Multinomial Naive Bayes: Multinomial Naive Bayes is preferred for usage on multinomial distributed data. It is commonly used in NLP text classification. Each text classification event represents the presence of a word in a document.\n",
        "3. Bernoulli Naive Bayes: Bernoulli Naive Bayes is employed when data is distributed using multivariate Bernoulli distributions. That is, several characteristics exist, but each is considered to have a binary value. As a result, features must be binary-valued."
      ],
      "metadata": {
        "id": "cqzSV-QyH3nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kWcQ_9u4IQcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Dataset"
      ],
      "metadata": {
        "id": "ibd_lsg9IQx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a collection of customer reviews from six of the review topics used in the paper by Blitzer et al., (2007) mentioned above. The data has been formatted so that there is one review per line, and the texts have been split into separate words (\"tokens\") and lowercased. \n",
        "\n",
        "url= http://www.cse.chalmers.se/~richajo/dit862/data/all_sentiment_shuffled.txt"
      ],
      "metadata": {
        "id": "AOPHGVo0IiJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required packages"
      ],
      "metadata": {
        "id": "hpdwRUKjJD7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "vKMMx6K8DFnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your PUT & POST data — but nowadays, just use the json method!"
      ],
      "metadata": {
        "id": "fBOgr4pFJXvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "1vWBslnNwBAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting data from url and storing in data_txt"
      ],
      "metadata": {
        "id": "D-nzm46uJZxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting data from URL with request package\n",
        "request_url = requests.get ('http://www.cse.chalmers.se/~richajo/dit862/data/all_sentiment_shuffled.txt')\n",
        "data_txt = request_url.text"
      ],
      "metadata": {
        "id": "af24CQRBwEax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "printing th data_txt"
      ],
      "metadata": {
        "id": "jjVpmQIYJor1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the data\n",
        "data_txt"
      ],
      "metadata": {
        "id": "rZ4Ob8OVwdDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Data pre-processing"
      ],
      "metadata": {
        "id": "C4O0G0q7J9ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line in the file is organized in columns:\n",
        "\n",
        "•\t0: topic category label (books, camera, dvd, health, music, or software)\n",
        "\n",
        "•\t1: sentiment polarity label (pos or neg)\n",
        "\n",
        "•\t2: document identifier\n",
        "\n",
        "•\t3 and on: the words in the document\n"
      ],
      "metadata": {
        "id": "4fmxnL6UKHfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the columns \n",
        "labels = []\n",
        "category= [] \n",
        "document_id = []\n",
        "words_review = []\n"
      ],
      "metadata": {
        "id": "acB_lrd_wgyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data_txt into required format with specified columns"
      ],
      "metadata": {
        "id": "0sREo4LTKgiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting the data into the columns\n",
        "for line in data_txt.splitlines():\n",
        "  labels.append(line.split()[1])\n",
        "  category.append(line.split()[0])\n",
        "  document_id.append(line.split()[2])\n",
        "  words_review.append(' '.join(token for token in line.split()[3:]))"
      ],
      "metadata": {
        "id": "agLCU0TL33WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating data frame with columns created"
      ],
      "metadata": {
        "id": "cUbr37C_K0Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the dataframe with columns ('labels','category','document_id','words_review') \n",
        "# ziping them\n",
        "df = pd.DataFrame(zip(labels,category,document_id,words_review ), columns = ['labels','category','document_id','words_review'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xIV8NXfK4fNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking any null values in the data"
      ],
      "metadata": {
        "id": "hcQipwigLULF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the null values in the dataframe\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "nv_3TE685pbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Data visualizations"
      ],
      "metadata": {
        "id": "5AyvFNi6L0D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the total number different values in the lables column\n",
        "count_labels = df['labels'].value_counts()"
      ],
      "metadata": {
        "id": "Ch2nSag253jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the count\n",
        "count_labels"
      ],
      "metadata": {
        "id": "2WHbiLaj6STQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a plot using seaborn, for the negative & postive values in the labels column"
      ],
      "metadata": {
        "id": "gzlW3mrTMEOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a plot for the count values with lables for negative & postive\n",
        "sns.countplot(data = df, x = 'labels')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "PPG55Ufc6Udi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting the str into int, by replacing negative values as '0' & postive as '1'"
      ],
      "metadata": {
        "id": "GXnbUF6dMsxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#assiging neg as '0' & pos as '1'\n",
        "df['labels'] = np.where(df['labels']!='pos', 0, 1)\n"
      ],
      "metadata": {
        "id": "uh_eecye6Yet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the df\n",
        "df"
      ],
      "metadata": {
        "id": "-ZtZ9RJV6nUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BjP1CuW-9ZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Splitting the data"
      ],
      "metadata": {
        "id": "tEbI9n-hNM7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bayes theorem is applied with the \"naive\" assumption of conditional independence between every pair of features given the value of the class variable in Navies Bayes approaches."
      ],
      "metadata": {
        "id": "kxpdrn1IRJ42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Without cleaning data"
      ],
      "metadata": {
        "id": "qGzojXJQ6pvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the train_test_split module from sklearn package"
      ],
      "metadata": {
        "id": "VFE64DKdNTk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "z60dMUig8N7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaring the words to x & labels to y"
      ],
      "metadata": {
        "id": "Yct3d982OuJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word_review to X value\n",
        "X = df['words_review']\n",
        "# labels to y values\n",
        "y = df['labels']"
      ],
      "metadata": {
        "id": "HS2Mblb-7Ucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the data with test size as 20% and random state as 42"
      ],
      "metadata": {
        "id": "KFJx3mLnNeLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating test and train data using train_test_split model with train size 80% & test size 20%, where random state is 42\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "2_rJ2A3LNe3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the shapes of train & test\n",
        "print ('The shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('The shapes of X_test, y_test: ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "K1P7ZQh3NhFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Applying the model"
      ],
      "metadata": {
        "id": "dS2PMlnoPsBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating matrix of token count from collection of text document"
      ],
      "metadata": {
        "id": "GxiXsBoPUZkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(lowercase = False)"
      ],
      "metadata": {
        "id": "tXbvxzRr8PG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the vectorizer model for training data"
      ],
      "metadata": {
        "id": "09P90SRBVqug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the vectorizer model into the training set\n",
        "X_train_vec_tfrm = vectorizer.fit_transform(X_train)\n",
        "#Creating dense matrix for train data\n",
        "X_train_vec_tfrm_den_mtrx = X_train_vec_tfrm.toarray()"
      ],
      "metadata": {
        "id": "oi2bIltr8SVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the shapes\n",
        "# the shape for tranformed X_train data\n",
        "print ('The shape of transformed X_train: ', X_train_vec_tfrm_den_mtrx.shape)\n",
        "# the shape for transformed y_train data\n",
        "print ('The shape of transformed y_train: ', y_train.shape)"
      ],
      "metadata": {
        "id": "7se5l96EVhTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the vectorizer model for test data"
      ],
      "metadata": {
        "id": "OTlQeJqdV2Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the vectorizer model into the test set\n",
        "X_test_vec_tfrm = vectorizer.transform(X_test)\n",
        "#Creating dense matrix for test data\n",
        "X_test_vec_tfrm_den_mtrx = X_test_vec_tfrm.toarray()\n",
        "# the shape of transformed X_test data\n",
        "print ('The shape of transformed X_test: ', X_test_vec_tfrm_den_mtrx.shape)\n",
        "# the shape of transformed y_test data\n",
        "print ('The shape of transformed y_test: ', y_test.shape)"
      ],
      "metadata": {
        "id": "vZTlZdE38XCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the length of vectorizer feature names\n",
        "print('The total no. of features: ', len(vectorizer.get_feature_names()))"
      ],
      "metadata": {
        "id": "5AiVn2Qx8bHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Naive Bayes models forr the text classififcation"
      ],
      "metadata": {
        "id": "XVd8rPK6XuKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the multinomial navie bayes module from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "M_nav_bys = MultinomialNB()"
      ],
      "metadata": {
        "id": "c6MIjRk38bu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model into the training set\n",
        "M_nav_bys.fit(X_train_vec_tfrm_den_mtrx, y_train)"
      ],
      "metadata": {
        "id": "11H6-XJo8iO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validating the model using k-fold cross validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv = cross_validate (M_nav_bys, X_train_vec_tfrm_den_mtrx, y_train, cv = 8)"
      ],
      "metadata": {
        "id": "9q8mQZAw8i3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Prediction results and test scores"
      ],
      "metadata": {
        "id": "XW_cBGqkas5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the accuracy score for cv=8 & mean"
      ],
      "metadata": {
        "id": "b8dnk7j7bEc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the accuracy score of 8-fold cross validation:\", cv['test_score'])"
      ],
      "metadata": {
        "id": "id7TRHqmZzs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the cross validation accuracy mean score: \", cv['test_score'].mean())"
      ],
      "metadata": {
        "id": "fah6uHW681zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the learnt model to make prediction on the test set\n",
        "y_pred = M_nav_bys.predict(X_test_vec_tfrm_den_mtrx)"
      ],
      "metadata": {
        "id": "SLiao9yz8nVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the test set\n",
        "print('the Accuracy of model in the test set : {:.3f}'.format(M_nav_bys.score(X_test_vec_tfrm_den_mtrx, y_test)))"
      ],
      "metadata": {
        "id": "DWbzQm_S8nYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Metrics"
      ],
      "metadata": {
        "id": "o4T7Oca9a2th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix for y_test & y_train"
      ],
      "metadata": {
        "id": "2AH93Wp0cBJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confn_matrix = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "5R-36v2U8nbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a image for confusion matrix heat map using seaborn package"
      ],
      "metadata": {
        "id": "qckb2FjrcI2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the confusion matrix\n",
        "sns.heatmap(confn_matrix, cmap=\"RdYlGn\", annot = True, fmt = '.0f')\n",
        "plt.xlabel ('The predicted values')\n",
        "plt.ylabel ('The actual values')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ehu_SB668xk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above confusion matrix,\n",
        " model correctly predicted 1015 negative reviews, and 945 positive reviews but the model incorrectly predicts 194 positive reviews as negative and 229 negative reviews as positive."
      ],
      "metadata": {
        "id": "ocCVpKvOl8IE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Conclusion"
      ],
      "metadata": {
        "id": "JvXPhUbhiAsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the ROC curve\n",
        "\n",
        "An ROC (Receiver Operating Characteristic Curve) is a graph showing the performance of a classification model at all classification thresholds.\n",
        "\n",
        "Higher the AUC is, the better the model performs. The AUC is expected to greater than 0.5, or over left-top part compared to the baseline.\n",
        "\n",
        "TPR: TPR is the probability that an actual positive will test positive.\n",
        "\n",
        "    TPR = TP/P = TP/(TP+FN)\n",
        "FPR: FPR is the model mistakenly predicted the positive class\n",
        "\n",
        "    FPR = FP/N = FP/ (FP+TN)"
      ],
      "metadata": {
        "id": "JcuzxYOBl2DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the ROC curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "Sfvox37scQEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_c1  = M_nav_bys.predict_proba (X_test_vec_tfrm_den_mtrx)[:,1]\n",
        "false_pstve_rte, true_pstve_rte, threshold = roc_curve (y_test, y_pred_prob_c1, pos_label = 1)\n",
        "roc_auc_score = roc_auc_score (y_test, y_pred_prob_c1)\n",
        "print('The ROC AUC score for y_test & y_pred_c1: ', roc_auc_score) "
      ],
      "metadata": {
        "id": "R5rdkSa08neX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the ROC Curve\n",
        "plt.plot (false_pstve_rte, true_pstve_rte)\n",
        "plt.plot([0,1], '--')\n",
        "plt.xlabel ('False Postive Rate')\n",
        "plt.ylabel('True Postive Rate')\n",
        "plt.title (\"the ROC Curve (AUC = {:.3f}) for y_test & y_pred_c1\".format(roc_auc_score))\n",
        "plt.grid()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "VT5f_25r8nhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is plotted between the true positive rate and the false positive rate at different thresholds.\n",
        "## The ROC curve area was found to be 0.883."
      ],
      "metadata": {
        "id": "sF70O9q1mqQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with cleaning the data "
      ],
      "metadata": {
        "id": "Acy_BefZ8nkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop_words"
      ],
      "metadata": {
        "id": "83dv5LvSiLMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stop_words import get_stop_words\n",
        "stop_words = get_stop_words('en')\n",
        "# Removing stopwords, and numerics\n",
        "df['words_review'] = df['words_review'].apply( lambda x: ' '.join([x for x in str(x).split() if x not in stop_words]) )  \n",
        "# Removing punctuations and non-letter tokens\n",
        "df['words_review']=df['words_review'].str.replace('[^\\w\\s]','') \n",
        "df['words_review'].head()"
      ],
      "metadata": {
        "id": "WkQFtqtP8nnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hWEWW7qiiKQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "SMuVLw8WjFka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word_review to X value\n",
        "X = df['words_review']\n",
        "# labels to y values\n",
        "y = df['labels']"
      ],
      "metadata": {
        "id": "kK0_5vTHjFkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating test and train data using train_test_split model with train size 80% & test size 20%, where random state is 42\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "9tkoXbASjFkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the shapes of train & test\n",
        "print (' the shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('the shapes of X_test, y_test: ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "axkNKy_6jFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(lowercase = False)"
      ],
      "metadata": {
        "id": "wwQJGeXQjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the vectorizer model into the training set\n",
        "X_train_vec_tfrm = vectorizer.fit_transform(X_train)\n",
        "#Creating dense matrix for train data\n",
        "X_train_vec_tfrm_den_mtrx = X_train_vec_tfrm.toarray()"
      ],
      "metadata": {
        "id": "BOT3xvoSjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the shapes\n",
        "# the shape for tranformed X_train data\n",
        "print ('The shape of transformed X_train: ', X_train_vec_tfrm_den_mtrx.shape)\n",
        "# the shape for transformed y_train data\n",
        "print ('The shape of transformed y_train: ', y_train.shape)"
      ],
      "metadata": {
        "id": "udeyHmjUjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the vectorizer model into the test set\n",
        "X_test_vec_tfrm = vectorizer.transform(X_test)\n",
        "#Creating dense matrix for test data\n",
        "X_test_vec_tfrm_den_mtrx = X_test_vec_tfrm.toarray()\n",
        "# the shape of transformed X_test data\n",
        "print ('The shape of transformed X_test: ', X_test_vec_tfrm_den_mtrx.shape)\n",
        "# the shape of transformed y_test data\n",
        "print ('The shape of transformed y_test: ', y_test.shape)"
      ],
      "metadata": {
        "id": "-LHcDX0njFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the length of vectorizer feature names\n",
        "print('The total no. of features: ', len(vectorizer.get_feature_names()))"
      ],
      "metadata": {
        "id": "LW5nVedMjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the multinomial navie bayes module from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "M_nav_bys = MultinomialNB()"
      ],
      "metadata": {
        "id": "HjFo2b84jFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model into the training set\n",
        "M_nav_bys.fit(X_train_vec_tfrm_den_mtrx, y_train)"
      ],
      "metadata": {
        "id": "-9uvIUWRjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validating the model using k-fold cross validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv = cross_validate (M_nav_bys, X_train_vec_tfrm_den_mtrx, y_train, cv = 8)"
      ],
      "metadata": {
        "id": "P1eBQcpFjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the accuracy score of 8-fold cross validation:\", cv['test_score'])"
      ],
      "metadata": {
        "id": "87Lwk38_jFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the cross validation accuracy mean score: \", cv['test_score'].mean())"
      ],
      "metadata": {
        "id": "-qtsCQxGjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the learnt model to make prediction on the test set\n",
        "y_pred = M_nav_bys.predict(X_test_vec_tfrm_den_mtrx)"
      ],
      "metadata": {
        "id": "ssZmXm0QjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the test set\n",
        "print('the Accuracy of model in the test set : {:.3f}'.format(M_nav_bys.score(X_test_vec_tfrm_den_mtrx, y_test)))"
      ],
      "metadata": {
        "id": "TroUZxzBjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confn_matrix = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "gls_Nn0xjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the confusion matrix\n",
        "sns.heatmap(confn_matrix, cmap=\"YlOrBr\", annot = True, fmt = '.0f')\n",
        "plt.xlabel ('the predicted values')\n",
        "plt.ylabel ('the actual values')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ZKk2ykFRjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the ROC curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "hH81_DiPjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_c1  = M_nav_bys.predict_proba (X_test_vec_tfrm_den_mtrx)[:,1]\n",
        "false_pstve_rte, true_pstve_rte, threshold = roc_curve (y_test, y_pred_prob_c1, pos_label = 1)\n",
        "roc_auc_score = roc_auc_score (y_test, y_pred_prob_c1)\n",
        "print('The ROC AUC for y_test & y_pred_c1: ', roc_auc_score) "
      ],
      "metadata": {
        "id": "iOSQV7crjFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the ROC Curve\n",
        "plt.plot (false_pstve_rte, true_pstve_rte)\n",
        "plt.plot([0,1], '--')\n",
        "plt.xlabel ('False Postive Rate')\n",
        "plt.ylabel('True Postive Rate')\n",
        "plt.title (\"the ROC Curve (AUC = {:.3f}) for y_test & y_pred_c1\".format(roc_auc_score))\n",
        "plt.grid()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "5NKpRAU5jFkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is plotted between the true positive rate and the false positive rate at different thresholds.\n",
        "## The ROC curve area was found to be 0.884."
      ],
      "metadata": {
        "id": "hLAHppcpnGQR"
      }
    }
  ]
}
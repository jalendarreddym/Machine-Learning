{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Maligireddy_assignment4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name:- Jalendar Reddy Maligireddy\n",
        "\n",
        "ID:- 11511290"
      ],
      "metadata": {
        "id": "lA-qJryEfUYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RANDOM FOREST**"
      ],
      "metadata": {
        "id": "_mqhvaEFfKeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. About the model"
      ],
      "metadata": {
        "id": "07-EvKH5f1Zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest is a Supervised Machine Learning Algorithm that is used widely in Classification and Regression problems. It builds decision trees on different samples and takes their majority vote for classification and average in case of regression.\n",
        "\n",
        "One of the most important features of the Random Forest Algorithm is that it can handle the data set containing continuous variables as in the case of regression and categorical variables as in the case of classification. It performs better results for classification problems."
      ],
      "metadata": {
        "id": "o_zqfFU-g1SD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two types of methods:\n",
        "\n",
        "1. Bagging– It creates a different training subset from sample training data with replacement & the final output is based on majority voting. For example,  Random Forest.\n",
        "\n",
        "2. Boosting– It combines weak learners into strong learners by creating sequential models such that the final model has the highest accuracy. For example,  ADA BOOST, XG BOOST"
      ],
      "metadata": {
        "id": "g6_A8sZlhEPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Dataset"
      ],
      "metadata": {
        "id": "MN7pFkQLhIPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set containing descriptive attributes of digitized images of a process known as, fine needle aspirate (FNA) of breast mass."
      ],
      "metadata": {
        "id": "_yeVr5gGf9kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a total of 29 features that were computed for each cell nucleus with an ID Number and the Diagnosis (Later converted to binary  representations: Malignant = 1, Benign = 0)."
      ],
      "metadata": {
        "id": "GxE7vRcVgIYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the pandas package\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HKS_6anSe9Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset with first column as index, named as dataframe"
      ],
      "metadata": {
        "id": "P04SHbv5h5eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset to dataframe\n",
        "#By using pandas reading csv file\n",
        "#index as first rows in dataset\n",
        "dataframe = pd.read_csv(\"data-breastCancer.csv\", index_col=0)"
      ],
      "metadata": {
        "id": "9mEq9yEfOfE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using the head function getting first 5 rows in the dataframe\n",
        "dataframe.head()"
      ],
      "metadata": {
        "id": "gUs2nfklO8yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using the tail function getting last 5 rows in the dataframe\n",
        "dataframe.tail()"
      ],
      "metadata": {
        "id": "z_QuWBeUO-Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data pre-processing"
      ],
      "metadata": {
        "id": "zeObo9wDiXh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#info gives details about dataset\n",
        "dataframe.info()"
      ],
      "metadata": {
        "id": "3EwLqTlwP_TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the missing values in the dataset"
      ],
      "metadata": {
        "id": "H_p2ZylViv2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.isnull().sum()"
      ],
      "metadata": {
        "id": "5IH2sXjXirlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 569 missing values in the unamed: 32 ccolumn"
      ],
      "metadata": {
        "id": "DjkkLKvqi99X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the number of rows and columns in the dataset, by using shape function"
      ],
      "metadata": {
        "id": "At4zNM4ojKb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to get number of rows and columns using shape\n",
        "dataframe.shape"
      ],
      "metadata": {
        "id": "lRx7CKLUQIDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the detail of the dataset, by using the describe function"
      ],
      "metadata": {
        "id": "ydSMWo-5jap9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the describe function, we can have the \n",
        "\n",
        "1.   Nummber of values in column\n",
        "2.   Mean of the column\n",
        "3.   Standard deviation of the column\n",
        "4.   minimum & maximum of the column\n",
        "5.   25%,50%,75% of the column\n",
        "\n"
      ],
      "metadata": {
        "id": "0tEYR3SIjpZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to detail explain of dataset using describe\n",
        "dataframe.describe()"
      ],
      "metadata": {
        "id": "aDTrF4DlQM9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the column names in the dataset\n",
        "dataframe.columns"
      ],
      "metadata": {
        "id": "pRtB7mg2QR7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get number of columns in the dataframe"
      ],
      "metadata": {
        "id": "FklaMvWJkSdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.core import count\n",
        "count(dataframe.columns)"
      ],
      "metadata": {
        "id": "1B16zzGnSbJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping the Unnamed: 32 column, and the new data is named as df"
      ],
      "metadata": {
        "id": "RCsx-jHZkXOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the df we are using id as index"
      ],
      "metadata": {
        "id": "MmrotQHYkkDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the unamed : 32 column and assigned the dataset to df\n",
        "df= dataframe.drop(['Unnamed: 32'],axis=1)"
      ],
      "metadata": {
        "id": "50KOJKx0Q6fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ttBxtyWKRMBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "9WOoQhawRovB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "1EoQRb6nRtV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking each column datatype"
      ],
      "metadata": {
        "id": "SkBA4QfPkqf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the data type of all columns\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "rzwtmuV1Rwbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting object datatype into int datatype"
      ],
      "metadata": {
        "id": "SMDqXscAkw6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converint object type into int type (0,1)\n",
        "# where in diagnosis M as 1 & B as 0\n",
        "df['diagnosis_value'] = df['diagnosis'].map({'M':1, 'B':0})"
      ],
      "metadata": {
        "id": "4oh1oCq0TgMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "lRmF5M8DTRN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping the diagnosis column, which is object type\n",
        "where we assigned new column diagnosis_value using diagnosis column to int type\n",
        "from diagnosis column M as 1 & B as 0"
      ],
      "metadata": {
        "id": "FrqXpYdzk2rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the object data type & assigned the data set to df\n",
        "df = df.drop(['diagnosis'],axis=1)"
      ],
      "metadata": {
        "id": "SfvEyYVSTR2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "q4NufBx-TeeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "36PHmxpJTqB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking any null values in the dataset\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Rd3_sB9oU0pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Data visualizations"
      ],
      "metadata": {
        "id": "SPc7U5m3lasm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a plot for the number of value\n",
        "import seaborn as sns\n",
        "sns.countplot(x='diagnosis_value', data=df)\n",
        "#getting number of different values count\n",
        "print(\"Number of 0's & 1's in the diagnosis_value :\\n\", df['diagnosis_value'].value_counts())"
      ],
      "metadata": {
        "id": "UfFsOy1eVN7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"diagnosis_value\" contains binary values: M as 1 (malignant) - 212 and B as 0 (benight) - 357"
      ],
      "metadata": {
        "id": "DJADPZaHmMLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare feature vector and target variable"
      ],
      "metadata": {
        "id": "AxPLZ6ASnKBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into x & y\n",
        "# X as all the dataset columns except 'diagnosis_value'\n",
        "# y as only 'diagnosis_value'\n",
        "X = df.drop(labels='diagnosis_value', axis=1)\n",
        "y = df['diagnosis_value']\n"
      ],
      "metadata": {
        "id": "iZm8oBL-XTZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Splitting the data"
      ],
      "metadata": {
        "id": "av8EcSoDnOgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the train_test_split model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O61NmMfAXosH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating test and train data using train_test_split model with train size 80% & test size 20%, where random state is 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wtE9gj87XrB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the shapes of train & test\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "E0ZgEPYKBomM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Applying the model"
      ],
      "metadata": {
        "id": "uSFPDmhGlpse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "inChxXKQX0V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_frst_clasfr = RandomForestClassifier(random_state=42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "2-u77Bv-zJaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-fold cross validation:**\n",
        "\n",
        "K-fold cv splits training data into K folds and iteratively fits the model k times, training on k-1 of the folds and assessing on the kth fold each time. Finally, the model's final validation metrics are calculated by averaging the performance on each of the folds."
      ],
      "metadata": {
        "id": "XiQtkKahm2NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "cv = cross_validate (rand_frst_clasfr, X_train, y_train, cv = 10)"
      ],
      "metadata": {
        "id": "uj_WSnCNCnSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy score of 10-fold cross validation: \", cv['test_score'])\n",
        "print(\"Accuracy mean score of CV: \", round(cv['test_score'].mean(),3))"
      ],
      "metadata": {
        "id": "KTFhDh5kCuHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With an accuracy rating of 0.96, the underlying version done brilliantly at the education set. However, through adjusting the hyperparameters, we will nonetheless enhance performance."
      ],
      "metadata": {
        "id": "JXQ-pxXCnzAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before fitting a rf model we need to tune the parameters to get the best model. Below parameters are tuned in this project.\n",
        "\n",
        "1.\tmax_depth\n",
        "2.\tmax_features\n",
        "3.\tcriterion\n",
        "4.  bootstrap"
      ],
      "metadata": {
        "id": "MzU49thEyxtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prm_dist = {'max_depth': [2, 3, 4],\n",
        "              'bootstrap': [True, False],\n",
        "              'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "print(prm_dist)"
      ],
      "metadata": {
        "id": "AXdo4KvKziH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the results :\n",
        "\n",
        "max_depth: [2, 3, 4]\n",
        "\n",
        "bootstrap: [True, False]\n",
        "\n",
        "max_features: ['auto', 'sqrt', 'log2', None]\n",
        "\n",
        "criterion: ['gini', 'entropy']\n"
      ],
      "metadata": {
        "id": "rODbp_KWy3x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Before tuning the parameters, the below values are passed to the random forest classifier and got the best parameters using best_params of GridSearchCV from the sklearn.\n"
      ],
      "metadata": {
        "id": "_tgE6brTysuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "-21T_TV70KdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_rand_frst = GridSearchCV(rand_frst_clasfr , cv = 10,\n",
        "                     param_grid=prm_dist, \n",
        "                     n_jobs = 3)"
      ],
      "metadata": {
        "id": "JNRmiyenz6Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_rand_frst.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iNvZGyWH0X5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Parameters using grid search: {0}'.format(cv_rand_frst.best_params_))"
      ],
      "metadata": {
        "id": "ceMC9dHu0cOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the result the best parameters are \n",
        "\n",
        "bootstrap: True \n",
        "\n",
        "criterion: entropy\n",
        "\n",
        "max_depth: 4\n",
        "\n",
        "max_features: log2\n"
      ],
      "metadata": {
        "id": "2rVeheBHzc7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the random forest model is fit by setting the parameter values after tuning."
      ],
      "metadata": {
        "id": "9X_7FwFkz-FQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging Classifier\n",
        "\n",
        "Bagging is an ensemble approach that fits multiple models to different subsets of a training dataset before combining the predictions of all the models. Random forest is a bagging extension that randomly selects a subset of the features used in each data sample. Both bagging forests and random forests have proven successful in a variety of predictive modeling problems. \n",
        "\n",
        " While effective,  they are not suitable for classification problems with a distorted class distribution. Nonetheless, some changes to the algorithms have been proposed, adjusting their behavior and making them more suitable for serious class imbalances."
      ],
      "metadata": {
        "id": "oEhykNjhyL-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "metadata": {
        "id": "QUqAND9n1w6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_clssfr = BaggingClassifier()"
      ],
      "metadata": {
        "id": "BCK5onaH1oAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ],
      "metadata": {
        "id": "ZHT2WEX92AwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)"
      ],
      "metadata": {
        "id": "rLwH-lrW1019"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "VG03VRgs2R7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrs = cross_val_score(bagging_clssfr, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)"
      ],
      "metadata": {
        "id": "3OPli7zX2ByQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean"
      ],
      "metadata": {
        "id": "76BvA1kY2i3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('BaggingClassifier model Mean ROC AUC : %.3f' % mean(scrs))"
      ],
      "metadata": {
        "id": "uqeCfCdZ2ViP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = cross_validate (bagging_clssfr, X_train, y_train, cv = 10)"
      ],
      "metadata": {
        "id": "ePReYTwoEZZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BaggingClassifier model Accuracy score of 10-fold cross validation: \", cv['test_score'])\n",
        "print(\"BaggingClassifier model Accuracy mean score of CV: \", cv['test_score'].mean())"
      ],
      "metadata": {
        "id": "H8TkcEHI3YPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_clssfr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8HRK5MYxEwfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Prediction results and test scores"
      ],
      "metadata": {
        "id": "kLdris8vl1fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making the prediction on the test set by using bagging classifer\n",
        "predict_data = bagging_clssfr.predict(X_test)\n",
        "\n",
        "# the estimating probability of the test set\n",
        "predict_probability = bagging_clssfr.predict_proba (X_test)\n"
      ],
      "metadata": {
        "id": "-1-CJm05Ewh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the predicted probability for class_0 & class_1\n",
        "print('class_0', 'class_1')\n",
        "print(predict_probability[:10])"
      ],
      "metadata": {
        "id": "1Xste0aIPtUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the acurracy scores for the tet set\n",
        "print('BaggingClassifier model Accuracy of the selected model in the test set: {:.3f}'.format(bagging_clssfr.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "AkHaIrBpEwk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plyt"
      ],
      "metadata": {
        "id": "znqJYvHoFil0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, predict_data )\n"
      ],
      "metadata": {
        "id": "Ee3O-lMTEwnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing confusion matrix\n",
        "sns.heatmap(conf_matrix, annot = True)\n",
        "plyt.xlabel ('BaggingClassifier model predicted values')\n",
        "plyt.ylabel ('BaggingClassifier model actual values')"
      ],
      "metadata": {
        "id": "PIKLyKhqRqX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above confusion matrix below results can be inferred\n",
        "\n",
        "In the test data set actually there are total 114 patient records among which 71 are actual 0s and 43 are actual 1s\n",
        "\n",
        "The random forest model we developed has predicted 1 record as 1s from out of 71 0s and 5 records as 0s out of 43 1s.\n"
      ],
      "metadata": {
        "id": "tJhzatKTpBM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Metrics"
      ],
      "metadata": {
        "id": "hP2E60oAl8DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "# the probability of the class_1 on the test set\n",
        "predicted_probability_class_1 = predict_probability[:,1]\n",
        "\n",
        "# True Positive Rate  and False Positive Rate \n",
        "false_post_rate, true_post_rate, threshold = roc_curve (y_test,predicted_probability_class_1)\n",
        "\n",
        "# the Area Under the ROC Curve (roc_auc)\n",
        "roc_auc_score = roc_auc_score (y_test,predicted_probability_class_1)\n",
        "print(\"BaggingClassifier model roc auc score : {:.3f}\".format(roc_auc_score))"
      ],
      "metadata": {
        "id": "POwpSheoEwtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A ROC (Receiver Operating Characteristic Curve) is a graph showing the performance of a classification model at all classification thresholds. The higher the \n",
        " AUC, the better the model behaves. The AUC is expected to be more than 0.5 above the upper left part of the baseline."
      ],
      "metadata": {
        "id": "bQSyGVXspDPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPR is the probability that an right positive will test positive.\n",
        "\n",
        "    TPR = TP/P = TP/(TP+FN)\n",
        "FPR is the model wrongly predicted the positive class\n",
        "\n",
        "    FPR = FP/N = FP/ (FP+TN)"
      ],
      "metadata": {
        "id": "Qs80geglpSVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predict_data))"
      ],
      "metadata": {
        "id": "JkSmVMD8pl1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the ROC Curve\n",
        "plyt.subplots(figsize = (8,5))\n",
        "plyt.plot( false_post_rate, true_post_rate, label='BaggingClassifier model Test AUC: %0.3f'%roc_auc_score)\n",
        "plyt.plot([0,1], '--')\n",
        "plyt.xlabel('BaggingClassifier model False Positive Rate')\n",
        "plyt.ylabel('BaggingClassifier model True Positive Rate')\n",
        "plyt.title (\"BaggingClassifier model ROC Curve (AUC = {:.3f})\".format(roc_auc_score))\n",
        "plyt.grid()\n",
        "plyt.show()"
      ],
      "metadata": {
        "id": "RhpcpfOuEwv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above ROC curve, The accuracy of the BaggingClassifier model is 0.97%."
      ],
      "metadata": {
        "id": "DL1mJDRb4GQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xLCnrtRKEwy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YeAiA-16Ew13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LUB7r4j7Ew4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "-70t9xYWEw7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_grid = {'n_estimators' :[int(x) for x in np.linspace(start = 100, stop = 1000, num = 10, endpoint = True)],\n",
        "             'max_features': ['auto', 'sqrt', 'log2'],\n",
        "             'max_depth': [int(x) for x in np.linspace(start = 3, stop = 36, num=33, endpoint = True)],\n",
        "             'min_samples_split': [5, 10, 15],\n",
        "             'min_samples_leaf': [3, 4, 5], \n",
        "             'bootstrap': ['True']}\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "Yc1zyOKLHBEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_grid ={'max_depth': [2, 3, 4],\n",
        "              'bootstrap': [True, False],\n",
        "              'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "Q_pd3BRVWsUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a base randomforest model for tuning\n",
        "tuning_randfrst_clssfr = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a randomized search cross validation model for searching for the best hyperparameters for the base rf model over 100 parameters combination\n",
        "random_search_rf = RandomizedSearchCV (estimator=tuning_randfrst_clssfr, param_distributions  = random_grid, random_state=42, cv = 10, n_iter=100)\n",
        "\n",
        "# fit the randomized search CV model into the training set\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(random_search_rf.best_params_)"
      ],
      "metadata": {
        "id": "z-Fa6-qUEw-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tuned random forest model with the best parameters choosen by  the cv randomized search algorithm\n",
        "tuned_randfrst_clssfr = RandomForestClassifier (n_estimators = 100, min_samples_split = 5, min_samples_leaf = 3, max_features = 'auto',  max_depth = 26, bootstrap = True, random_state=42)\n",
        "\n",
        "# Validating the model using k-fold cross validation (k=10)\n",
        "tuned_cv = cross_validate (tuned_randfrst_clssfr, X_train, y_train, cv = 10)\n",
        "print(\"RandomForestClassifier model Accuracy score: \", tuned_cv['test_score'])\n",
        "print(\"RandomForestClassifier model Accuracy mean score of CV: \", tuned_cv['test_score'].mean())"
      ],
      "metadata": {
        "id": "a9feWykkHPYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the selected model to the training set\n",
        "tuned_randfrst_clssfr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jDEoQxD3ExBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the selected model to make prediction on the test set\n",
        "pred = tuned_randfrst_clssfr.predict(X_test)\n",
        "\n",
        "# Observing the estimate probability of classess in the test set\n",
        "pred_prob = tuned_randfrst_clssfr.predict_proba (X_test)\n",
        "print ('class_0', 'class_1')\n",
        "print(pred_prob[:10])"
      ],
      "metadata": {
        "id": "U4GXG2F9ExD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the acurracy scores for the tet set\n",
        "print('RandomForestClassifier model Accuracy of the selected model in the test set: {:.2f}'.format(tuned_randfrst_clssfr.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "YDpFz_LsExG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, pred )\n",
        "# visualizing confusion matrix\n",
        "sns.heatmap(conf_matrix, annot = True)\n",
        "plyt.xlabel ('RandomForestClassifier model predicted values')\n",
        "plyt.ylabel ('RandomForestClassifier model actual values')"
      ],
      "metadata": {
        "id": "jGvW9ePvExJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "#the probability of the class_1 on the test set\n",
        "pred_prob_c1 = pred_prob[:,1]\n",
        "\n",
        "# True Positive Rate and False Positive Rate \n",
        "false_post_rate, true_post_rate, threshold = roc_curve (y_test,pred_prob_c1, pos_label = 1)\n",
        "\n",
        "# the Area Under the ROC Curve \n",
        "roc_auc_score = roc_auc_score (y_test,pred_prob_c1)\n",
        "print(\"RandomForestClassifier model Roc AUC Score : \",round(roc_auc_score,2))"
      ],
      "metadata": {
        "id": "vktykgcFExMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the ROC Curve\n",
        "plyt.subplots(figsize = (8,5))\n",
        "plyt.plot( false_post_rate, true_post_rate, label='Test AUC: %0.3f'%roc_auc_score)\n",
        "plyt.plot([0,1], '--')\n",
        "plyt.xlabel('RandomForestClassifier model False Positive Rate')\n",
        "plyt.ylabel('RandomForestClassifier model True Positive Rate')\n",
        "plyt.title (\"RandomForestClassifier model ROC Curve (AUC = {:.3f})\".format(roc_auc_score))\n",
        "plyt.grid()\n",
        "plyt.show();"
      ],
      "metadata": {
        "id": "O7-XBjAyHhEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion**"
      ],
      "metadata": {
        "id": "TMB413Uf0Lws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above ROC curve, The accuracy of the RandomForestClassifier model is 0.99%."
      ],
      "metadata": {
        "id": "zrERdR510ihy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above ROC curve, The accuracy of the BaggingClassifier model is 0.97%."
      ],
      "metadata": {
        "id": "LxeCBW0k4Qb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the both, we can conclude that  RandomForestClassifier model is best with 0.99%"
      ],
      "metadata": {
        "id": "-bHJ41Uq4Slm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SGf7aOMl4cB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}